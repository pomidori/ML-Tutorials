{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First downloand the imdb data set from the following url:\n",
    "http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "\n",
    "Then place the extracted folder named \"aclImdb\" inside the \"data\" folder in the same directory level as this jupyternotebook as\n",
    "data/aclImdb/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/i318656/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Sequential  # This does not work!# from  \n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.data_dir = \"data/IMDB/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text, y_train = imdb.load_data(train=True)\n",
    "x_test_text, y_test = imdb.load_data(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set size:  25000\n",
      "Test-set size:   25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Train-set size: \", len(x_train_text))\n",
    "print(\"Test-set size:  \", len(x_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = x_train_text + x_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV\\'s \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina\\'s pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D\\'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary\\'s Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.16 s, sys: 55.3 ms, total: 7.22 s\n",
      "Wall time: 7.23 s\n"
     ]
    }
   ],
   "source": [
    "%%%time\n",
    "tokenizer.fit_on_texts(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_words is None:\n",
    "    num_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'br': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'i': 10,\n",
       " 'this': 11,\n",
       " 'that': 12,\n",
       " 'was': 13,\n",
       " 'as': 14,\n",
       " 'for': 15,\n",
       " 'with': 16,\n",
       " 'movie': 17,\n",
       " 'but': 18,\n",
       " 'film': 19,\n",
       " 'on': 20,\n",
       " 'not': 21,\n",
       " 'you': 22,\n",
       " 'are': 23,\n",
       " 'his': 24,\n",
       " 'have': 25,\n",
       " 'be': 26,\n",
       " 'one': 27,\n",
       " 'he': 28,\n",
       " 'all': 29,\n",
       " 'at': 30,\n",
       " 'by': 31,\n",
       " 'an': 32,\n",
       " 'they': 33,\n",
       " 'so': 34,\n",
       " 'who': 35,\n",
       " 'from': 36,\n",
       " 'like': 37,\n",
       " 'or': 38,\n",
       " 'just': 39,\n",
       " 'her': 40,\n",
       " 'out': 41,\n",
       " 'about': 42,\n",
       " 'if': 43,\n",
       " \"it's\": 44,\n",
       " 'has': 45,\n",
       " 'there': 46,\n",
       " 'some': 47,\n",
       " 'what': 48,\n",
       " 'good': 49,\n",
       " 'when': 50,\n",
       " 'more': 51,\n",
       " 'very': 52,\n",
       " 'up': 53,\n",
       " 'no': 54,\n",
       " 'time': 55,\n",
       " 'my': 56,\n",
       " 'even': 57,\n",
       " 'would': 58,\n",
       " 'she': 59,\n",
       " 'which': 60,\n",
       " 'only': 61,\n",
       " 'really': 62,\n",
       " 'see': 63,\n",
       " 'story': 64,\n",
       " 'their': 65,\n",
       " 'had': 66,\n",
       " 'can': 67,\n",
       " 'me': 68,\n",
       " 'well': 69,\n",
       " 'were': 70,\n",
       " 'than': 71,\n",
       " 'much': 72,\n",
       " 'we': 73,\n",
       " 'bad': 74,\n",
       " 'been': 75,\n",
       " 'get': 76,\n",
       " 'do': 77,\n",
       " 'great': 78,\n",
       " 'other': 79,\n",
       " 'will': 80,\n",
       " 'also': 81,\n",
       " 'into': 82,\n",
       " 'people': 83,\n",
       " 'because': 84,\n",
       " 'how': 85,\n",
       " 'first': 86,\n",
       " 'him': 87,\n",
       " 'most': 88,\n",
       " \"don't\": 89,\n",
       " 'made': 90,\n",
       " 'then': 91,\n",
       " 'its': 92,\n",
       " 'them': 93,\n",
       " 'make': 94,\n",
       " 'way': 95,\n",
       " 'too': 96,\n",
       " 'movies': 97,\n",
       " 'could': 98,\n",
       " 'any': 99,\n",
       " 'after': 100,\n",
       " 'think': 101,\n",
       " 'characters': 102,\n",
       " 'watch': 103,\n",
       " 'films': 104,\n",
       " 'two': 105,\n",
       " 'many': 106,\n",
       " 'seen': 107,\n",
       " 'character': 108,\n",
       " 'being': 109,\n",
       " 'never': 110,\n",
       " 'plot': 111,\n",
       " 'love': 112,\n",
       " 'acting': 113,\n",
       " 'life': 114,\n",
       " 'did': 115,\n",
       " 'best': 116,\n",
       " 'where': 117,\n",
       " 'know': 118,\n",
       " 'show': 119,\n",
       " 'little': 120,\n",
       " 'over': 121,\n",
       " 'off': 122,\n",
       " 'ever': 123,\n",
       " 'does': 124,\n",
       " 'your': 125,\n",
       " 'better': 126,\n",
       " 'end': 127,\n",
       " 'man': 128,\n",
       " 'scene': 129,\n",
       " 'still': 130,\n",
       " 'say': 131,\n",
       " 'these': 132,\n",
       " 'here': 133,\n",
       " 'scenes': 134,\n",
       " 'why': 135,\n",
       " 'while': 136,\n",
       " 'something': 137,\n",
       " 'such': 138,\n",
       " 'go': 139,\n",
       " 'through': 140,\n",
       " 'back': 141,\n",
       " 'should': 142,\n",
       " 'those': 143,\n",
       " 'real': 144,\n",
       " \"i'm\": 145,\n",
       " 'now': 146,\n",
       " 'watching': 147,\n",
       " 'thing': 148,\n",
       " \"doesn't\": 149,\n",
       " 'actors': 150,\n",
       " 'though': 151,\n",
       " 'funny': 152,\n",
       " 'years': 153,\n",
       " \"didn't\": 154,\n",
       " 'old': 155,\n",
       " '10': 156,\n",
       " 'another': 157,\n",
       " 'work': 158,\n",
       " 'before': 159,\n",
       " 'actually': 160,\n",
       " 'nothing': 161,\n",
       " 'makes': 162,\n",
       " 'look': 163,\n",
       " 'director': 164,\n",
       " 'find': 165,\n",
       " 'going': 166,\n",
       " 'same': 167,\n",
       " 'new': 168,\n",
       " 'lot': 169,\n",
       " 'every': 170,\n",
       " 'few': 171,\n",
       " 'again': 172,\n",
       " 'part': 173,\n",
       " 'cast': 174,\n",
       " 'down': 175,\n",
       " 'us': 176,\n",
       " 'things': 177,\n",
       " 'want': 178,\n",
       " 'quite': 179,\n",
       " 'pretty': 180,\n",
       " 'world': 181,\n",
       " 'horror': 182,\n",
       " 'around': 183,\n",
       " 'seems': 184,\n",
       " \"can't\": 185,\n",
       " 'young': 186,\n",
       " 'take': 187,\n",
       " 'however': 188,\n",
       " 'got': 189,\n",
       " 'thought': 190,\n",
       " 'big': 191,\n",
       " 'fact': 192,\n",
       " 'enough': 193,\n",
       " 'long': 194,\n",
       " 'both': 195,\n",
       " \"that's\": 196,\n",
       " 'give': 197,\n",
       " \"i've\": 198,\n",
       " 'own': 199,\n",
       " 'may': 200,\n",
       " 'between': 201,\n",
       " 'comedy': 202,\n",
       " 'right': 203,\n",
       " 'series': 204,\n",
       " 'action': 205,\n",
       " 'must': 206,\n",
       " 'music': 207,\n",
       " 'without': 208,\n",
       " 'times': 209,\n",
       " 'saw': 210,\n",
       " 'always': 211,\n",
       " 'original': 212,\n",
       " \"isn't\": 213,\n",
       " 'role': 214,\n",
       " 'come': 215,\n",
       " 'almost': 216,\n",
       " 'gets': 217,\n",
       " 'interesting': 218,\n",
       " 'guy': 219,\n",
       " 'point': 220,\n",
       " 'done': 221,\n",
       " \"there's\": 222,\n",
       " 'whole': 223,\n",
       " 'least': 224,\n",
       " 'far': 225,\n",
       " 'bit': 226,\n",
       " 'script': 227,\n",
       " 'minutes': 228,\n",
       " 'feel': 229,\n",
       " '2': 230,\n",
       " 'anything': 231,\n",
       " 'making': 232,\n",
       " 'might': 233,\n",
       " 'since': 234,\n",
       " 'am': 235,\n",
       " 'family': 236,\n",
       " \"he's\": 237,\n",
       " 'last': 238,\n",
       " 'probably': 239,\n",
       " 'tv': 240,\n",
       " 'performance': 241,\n",
       " 'kind': 242,\n",
       " 'away': 243,\n",
       " 'yet': 244,\n",
       " 'fun': 245,\n",
       " 'worst': 246,\n",
       " 'sure': 247,\n",
       " 'rather': 248,\n",
       " 'hard': 249,\n",
       " 'anyone': 250,\n",
       " 'girl': 251,\n",
       " 'each': 252,\n",
       " 'played': 253,\n",
       " 'day': 254,\n",
       " 'found': 255,\n",
       " 'looking': 256,\n",
       " 'woman': 257,\n",
       " 'screen': 258,\n",
       " 'although': 259,\n",
       " 'our': 260,\n",
       " 'especially': 261,\n",
       " 'believe': 262,\n",
       " 'having': 263,\n",
       " 'trying': 264,\n",
       " 'course': 265,\n",
       " 'dvd': 266,\n",
       " 'everything': 267,\n",
       " 'set': 268,\n",
       " 'goes': 269,\n",
       " 'comes': 270,\n",
       " 'put': 271,\n",
       " 'ending': 272,\n",
       " 'maybe': 273,\n",
       " 'place': 274,\n",
       " 'book': 275,\n",
       " 'shows': 276,\n",
       " 'three': 277,\n",
       " 'worth': 278,\n",
       " 'different': 279,\n",
       " 'main': 280,\n",
       " 'once': 281,\n",
       " 'sense': 282,\n",
       " 'american': 283,\n",
       " 'reason': 284,\n",
       " 'looks': 285,\n",
       " 'effects': 286,\n",
       " 'watched': 287,\n",
       " 'play': 288,\n",
       " 'true': 289,\n",
       " 'money': 290,\n",
       " 'actor': 291,\n",
       " \"wasn't\": 292,\n",
       " 'job': 293,\n",
       " 'together': 294,\n",
       " 'war': 295,\n",
       " 'someone': 296,\n",
       " 'plays': 297,\n",
       " 'instead': 298,\n",
       " 'high': 299,\n",
       " 'during': 300,\n",
       " 'year': 301,\n",
       " 'said': 302,\n",
       " 'half': 303,\n",
       " 'everyone': 304,\n",
       " 'later': 305,\n",
       " 'takes': 306,\n",
       " '1': 307,\n",
       " 'seem': 308,\n",
       " 'audience': 309,\n",
       " 'special': 310,\n",
       " 'beautiful': 311,\n",
       " 'left': 312,\n",
       " 'himself': 313,\n",
       " 'seeing': 314,\n",
       " 'john': 315,\n",
       " 'night': 316,\n",
       " 'black': 317,\n",
       " 'version': 318,\n",
       " 'shot': 319,\n",
       " 'excellent': 320,\n",
       " 'idea': 321,\n",
       " 'house': 322,\n",
       " 'mind': 323,\n",
       " 'star': 324,\n",
       " 'wife': 325,\n",
       " 'fan': 326,\n",
       " 'death': 327,\n",
       " 'used': 328,\n",
       " 'else': 329,\n",
       " 'simply': 330,\n",
       " 'nice': 331,\n",
       " 'budget': 332,\n",
       " 'poor': 333,\n",
       " 'short': 334,\n",
       " 'completely': 335,\n",
       " 'second': 336,\n",
       " \"you're\": 337,\n",
       " '3': 338,\n",
       " 'read': 339,\n",
       " 'less': 340,\n",
       " 'along': 341,\n",
       " 'top': 342,\n",
       " 'help': 343,\n",
       " 'home': 344,\n",
       " 'men': 345,\n",
       " 'either': 346,\n",
       " 'line': 347,\n",
       " 'boring': 348,\n",
       " 'dead': 349,\n",
       " 'friends': 350,\n",
       " 'kids': 351,\n",
       " 'try': 352,\n",
       " 'production': 353,\n",
       " 'enjoy': 354,\n",
       " 'camera': 355,\n",
       " 'use': 356,\n",
       " 'wrong': 357,\n",
       " 'given': 358,\n",
       " 'low': 359,\n",
       " 'classic': 360,\n",
       " 'father': 361,\n",
       " 'need': 362,\n",
       " 'full': 363,\n",
       " 'stupid': 364,\n",
       " 'next': 365,\n",
       " 'until': 366,\n",
       " 'performances': 367,\n",
       " 'school': 368,\n",
       " 'hollywood': 369,\n",
       " 'rest': 370,\n",
       " 'truly': 371,\n",
       " 'awful': 372,\n",
       " 'video': 373,\n",
       " 'couple': 374,\n",
       " 'start': 375,\n",
       " 'sex': 376,\n",
       " 'recommend': 377,\n",
       " 'women': 378,\n",
       " 'let': 379,\n",
       " 'tell': 380,\n",
       " 'terrible': 381,\n",
       " 'remember': 382,\n",
       " 'mean': 383,\n",
       " 'came': 384,\n",
       " 'getting': 385,\n",
       " 'understand': 386,\n",
       " 'perhaps': 387,\n",
       " 'moments': 388,\n",
       " 'name': 389,\n",
       " 'keep': 390,\n",
       " 'face': 391,\n",
       " 'itself': 392,\n",
       " 'wonderful': 393,\n",
       " 'playing': 394,\n",
       " 'human': 395,\n",
       " 'style': 396,\n",
       " 'small': 397,\n",
       " 'episode': 398,\n",
       " 'perfect': 399,\n",
       " 'others': 400,\n",
       " 'person': 401,\n",
       " 'doing': 402,\n",
       " 'often': 403,\n",
       " 'early': 404,\n",
       " 'stars': 405,\n",
       " 'definitely': 406,\n",
       " 'written': 407,\n",
       " 'head': 408,\n",
       " 'lines': 409,\n",
       " 'dialogue': 410,\n",
       " 'gives': 411,\n",
       " 'piece': 412,\n",
       " \"couldn't\": 413,\n",
       " 'went': 414,\n",
       " 'finally': 415,\n",
       " 'mother': 416,\n",
       " 'case': 417,\n",
       " 'title': 418,\n",
       " 'absolutely': 419,\n",
       " 'live': 420,\n",
       " 'boy': 421,\n",
       " 'yes': 422,\n",
       " 'laugh': 423,\n",
       " 'certainly': 424,\n",
       " 'liked': 425,\n",
       " 'become': 426,\n",
       " 'entertaining': 427,\n",
       " 'worse': 428,\n",
       " 'oh': 429,\n",
       " 'sort': 430,\n",
       " 'loved': 431,\n",
       " 'lost': 432,\n",
       " 'hope': 433,\n",
       " 'called': 434,\n",
       " 'picture': 435,\n",
       " 'felt': 436,\n",
       " 'overall': 437,\n",
       " 'entire': 438,\n",
       " 'mr': 439,\n",
       " 'several': 440,\n",
       " 'based': 441,\n",
       " 'supposed': 442,\n",
       " 'cinema': 443,\n",
       " 'friend': 444,\n",
       " 'guys': 445,\n",
       " 'sound': 446,\n",
       " '5': 447,\n",
       " 'problem': 448,\n",
       " 'drama': 449,\n",
       " 'against': 450,\n",
       " 'waste': 451,\n",
       " 'white': 452,\n",
       " 'beginning': 453,\n",
       " '4': 454,\n",
       " 'fans': 455,\n",
       " 'totally': 456,\n",
       " 'dark': 457,\n",
       " 'care': 458,\n",
       " 'direction': 459,\n",
       " 'humor': 460,\n",
       " 'wanted': 461,\n",
       " \"she's\": 462,\n",
       " 'seemed': 463,\n",
       " 'under': 464,\n",
       " 'game': 465,\n",
       " 'children': 466,\n",
       " 'despite': 467,\n",
       " 'lives': 468,\n",
       " 'lead': 469,\n",
       " 'guess': 470,\n",
       " 'example': 471,\n",
       " 'already': 472,\n",
       " 'final': 473,\n",
       " \"you'll\": 474,\n",
       " 'throughout': 475,\n",
       " 'evil': 476,\n",
       " 'turn': 477,\n",
       " 'becomes': 478,\n",
       " 'unfortunately': 479,\n",
       " 'able': 480,\n",
       " 'quality': 481,\n",
       " \"i'd\": 482,\n",
       " 'days': 483,\n",
       " 'history': 484,\n",
       " 'fine': 485,\n",
       " 'side': 486,\n",
       " 'wants': 487,\n",
       " 'horrible': 488,\n",
       " 'heart': 489,\n",
       " 'writing': 490,\n",
       " 'amazing': 491,\n",
       " 'b': 492,\n",
       " 'flick': 493,\n",
       " 'killer': 494,\n",
       " 'run': 495,\n",
       " 'son': 496,\n",
       " '\\x96': 497,\n",
       " 'michael': 498,\n",
       " 'works': 499,\n",
       " 'close': 500,\n",
       " \"they're\": 501,\n",
       " 'act': 502,\n",
       " 'art': 503,\n",
       " 'kill': 504,\n",
       " 'matter': 505,\n",
       " 'etc': 506,\n",
       " 'tries': 507,\n",
       " \"won't\": 508,\n",
       " 'past': 509,\n",
       " 'town': 510,\n",
       " 'enjoyed': 511,\n",
       " 'turns': 512,\n",
       " 'brilliant': 513,\n",
       " 'gave': 514,\n",
       " 'behind': 515,\n",
       " 'parts': 516,\n",
       " 'stuff': 517,\n",
       " 'genre': 518,\n",
       " 'eyes': 519,\n",
       " 'car': 520,\n",
       " 'favorite': 521,\n",
       " 'directed': 522,\n",
       " 'late': 523,\n",
       " 'hand': 524,\n",
       " 'expect': 525,\n",
       " 'soon': 526,\n",
       " 'hour': 527,\n",
       " 'obviously': 528,\n",
       " 'themselves': 529,\n",
       " 'sometimes': 530,\n",
       " 'killed': 531,\n",
       " 'actress': 532,\n",
       " 'thinking': 533,\n",
       " 'child': 534,\n",
       " 'girls': 535,\n",
       " 'viewer': 536,\n",
       " 'starts': 537,\n",
       " 'myself': 538,\n",
       " 'city': 539,\n",
       " 'decent': 540,\n",
       " 'highly': 541,\n",
       " 'stop': 542,\n",
       " 'type': 543,\n",
       " 'self': 544,\n",
       " 'god': 545,\n",
       " 'says': 546,\n",
       " 'group': 547,\n",
       " 'anyway': 548,\n",
       " 'voice': 549,\n",
       " 'took': 550,\n",
       " 'known': 551,\n",
       " 'blood': 552,\n",
       " 'kid': 553,\n",
       " 'heard': 554,\n",
       " 'happens': 555,\n",
       " 'except': 556,\n",
       " 'fight': 557,\n",
       " 'feeling': 558,\n",
       " 'experience': 559,\n",
       " 'coming': 560,\n",
       " 'slow': 561,\n",
       " 'daughter': 562,\n",
       " 'writer': 563,\n",
       " 'stories': 564,\n",
       " 'moment': 565,\n",
       " 'leave': 566,\n",
       " 'told': 567,\n",
       " 'extremely': 568,\n",
       " 'score': 569,\n",
       " 'violence': 570,\n",
       " 'police': 571,\n",
       " 'involved': 572,\n",
       " 'strong': 573,\n",
       " 'chance': 574,\n",
       " 'lack': 575,\n",
       " 'cannot': 576,\n",
       " 'hit': 577,\n",
       " 'roles': 578,\n",
       " 'hilarious': 579,\n",
       " 's': 580,\n",
       " 'wonder': 581,\n",
       " 'happen': 582,\n",
       " 'particularly': 583,\n",
       " 'ok': 584,\n",
       " 'including': 585,\n",
       " 'living': 586,\n",
       " 'save': 587,\n",
       " 'looked': 588,\n",
       " \"wouldn't\": 589,\n",
       " 'crap': 590,\n",
       " 'please': 591,\n",
       " 'simple': 592,\n",
       " 'cool': 593,\n",
       " 'murder': 594,\n",
       " 'obvious': 595,\n",
       " 'happened': 596,\n",
       " 'complete': 597,\n",
       " 'cut': 598,\n",
       " 'serious': 599,\n",
       " 'age': 600,\n",
       " 'gore': 601,\n",
       " 'attempt': 602,\n",
       " 'hell': 603,\n",
       " 'ago': 604,\n",
       " 'song': 605,\n",
       " 'shown': 606,\n",
       " 'taken': 607,\n",
       " 'english': 608,\n",
       " 'james': 609,\n",
       " 'robert': 610,\n",
       " 'david': 611,\n",
       " 'seriously': 612,\n",
       " 'released': 613,\n",
       " 'reality': 614,\n",
       " 'opening': 615,\n",
       " 'interest': 616,\n",
       " 'jokes': 617,\n",
       " 'across': 618,\n",
       " 'none': 619,\n",
       " 'hero': 620,\n",
       " 'exactly': 621,\n",
       " 'possible': 622,\n",
       " 'today': 623,\n",
       " 'alone': 624,\n",
       " 'sad': 625,\n",
       " 'brother': 626,\n",
       " 'number': 627,\n",
       " 'career': 628,\n",
       " 'saying': 629,\n",
       " \"film's\": 630,\n",
       " 'hours': 631,\n",
       " 'usually': 632,\n",
       " 'cinematography': 633,\n",
       " 'talent': 634,\n",
       " 'view': 635,\n",
       " 'yourself': 636,\n",
       " 'annoying': 637,\n",
       " 'running': 638,\n",
       " 'relationship': 639,\n",
       " 'documentary': 640,\n",
       " 'wish': 641,\n",
       " 'huge': 642,\n",
       " 'order': 643,\n",
       " 'shots': 644,\n",
       " 'whose': 645,\n",
       " 'ridiculous': 646,\n",
       " 'taking': 647,\n",
       " 'important': 648,\n",
       " 'light': 649,\n",
       " 'body': 650,\n",
       " 'middle': 651,\n",
       " 'level': 652,\n",
       " 'ends': 653,\n",
       " 'female': 654,\n",
       " 'started': 655,\n",
       " 'call': 656,\n",
       " \"i'll\": 657,\n",
       " 'husband': 658,\n",
       " 'four': 659,\n",
       " 'power': 660,\n",
       " 'word': 661,\n",
       " 'turned': 662,\n",
       " 'major': 663,\n",
       " 'opinion': 664,\n",
       " 'change': 665,\n",
       " 'mostly': 666,\n",
       " 'usual': 667,\n",
       " 'silly': 668,\n",
       " 'scary': 669,\n",
       " 'rating': 670,\n",
       " 'beyond': 671,\n",
       " 'somewhat': 672,\n",
       " 'happy': 673,\n",
       " 'ones': 674,\n",
       " 'words': 675,\n",
       " 'room': 676,\n",
       " 'knew': 677,\n",
       " 'knows': 678,\n",
       " 'country': 679,\n",
       " 'disappointed': 680,\n",
       " 'talking': 681,\n",
       " 'novel': 682,\n",
       " 'apparently': 683,\n",
       " 'non': 684,\n",
       " 'strange': 685,\n",
       " 'upon': 686,\n",
       " 'attention': 687,\n",
       " 'finds': 688,\n",
       " 'single': 689,\n",
       " 'basically': 690,\n",
       " 'cheap': 691,\n",
       " 'modern': 692,\n",
       " 'due': 693,\n",
       " 'jack': 694,\n",
       " 'television': 695,\n",
       " 'musical': 696,\n",
       " 'problems': 697,\n",
       " 'miss': 698,\n",
       " 'episodes': 699,\n",
       " 'clearly': 700,\n",
       " 'local': 701,\n",
       " '7': 702,\n",
       " 'british': 703,\n",
       " 'thriller': 704,\n",
       " 'talk': 705,\n",
       " 'events': 706,\n",
       " 'five': 707,\n",
       " 'sequence': 708,\n",
       " \"aren't\": 709,\n",
       " 'class': 710,\n",
       " 'french': 711,\n",
       " 'moving': 712,\n",
       " 'ten': 713,\n",
       " 'fast': 714,\n",
       " 'earth': 715,\n",
       " 'review': 716,\n",
       " 'tells': 717,\n",
       " 'predictable': 718,\n",
       " 'songs': 719,\n",
       " 'team': 720,\n",
       " 'comic': 721,\n",
       " 'straight': 722,\n",
       " 'whether': 723,\n",
       " '8': 724,\n",
       " 'die': 725,\n",
       " 'add': 726,\n",
       " 'dialog': 727,\n",
       " 'entertainment': 728,\n",
       " 'above': 729,\n",
       " 'sets': 730,\n",
       " 'future': 731,\n",
       " 'enjoyable': 732,\n",
       " 'appears': 733,\n",
       " 'near': 734,\n",
       " 'space': 735,\n",
       " 'easily': 736,\n",
       " 'hate': 737,\n",
       " 'soundtrack': 738,\n",
       " 'bring': 739,\n",
       " 'giving': 740,\n",
       " 'lots': 741,\n",
       " 'similar': 742,\n",
       " 'romantic': 743,\n",
       " 'george': 744,\n",
       " 'supporting': 745,\n",
       " 'release': 746,\n",
       " 'mention': 747,\n",
       " 'within': 748,\n",
       " 'filmed': 749,\n",
       " 'message': 750,\n",
       " 'sequel': 751,\n",
       " 'clear': 752,\n",
       " 'falls': 753,\n",
       " 'needs': 754,\n",
       " \"haven't\": 755,\n",
       " 'dull': 756,\n",
       " 'suspense': 757,\n",
       " 'eye': 758,\n",
       " 'bunch': 759,\n",
       " 'surprised': 760,\n",
       " 'showing': 761,\n",
       " 'sorry': 762,\n",
       " 'tried': 763,\n",
       " 'certain': 764,\n",
       " 'easy': 765,\n",
       " 'working': 766,\n",
       " 'ways': 767,\n",
       " 'theme': 768,\n",
       " 'theater': 769,\n",
       " 'among': 770,\n",
       " 'named': 771,\n",
       " \"what's\": 772,\n",
       " 'storyline': 773,\n",
       " 'monster': 774,\n",
       " 'king': 775,\n",
       " 'stay': 776,\n",
       " 'effort': 777,\n",
       " 'stand': 778,\n",
       " 'minute': 779,\n",
       " 'fall': 780,\n",
       " 'gone': 781,\n",
       " 'rock': 782,\n",
       " 'using': 783,\n",
       " '9': 784,\n",
       " 'feature': 785,\n",
       " 'comments': 786,\n",
       " 'buy': 787,\n",
       " \"'\": 788,\n",
       " 'typical': 789,\n",
       " 't': 790,\n",
       " 'sister': 791,\n",
       " 'editing': 792,\n",
       " 'tale': 793,\n",
       " 'avoid': 794,\n",
       " 'mystery': 795,\n",
       " 'deal': 796,\n",
       " 'dr': 797,\n",
       " 'doubt': 798,\n",
       " 'fantastic': 799,\n",
       " 'nearly': 800,\n",
       " 'kept': 801,\n",
       " 'okay': 802,\n",
       " 'subject': 803,\n",
       " 'feels': 804,\n",
       " 'viewing': 805,\n",
       " 'elements': 806,\n",
       " 'oscar': 807,\n",
       " 'check': 808,\n",
       " 'realistic': 809,\n",
       " 'points': 810,\n",
       " 'means': 811,\n",
       " 'greatest': 812,\n",
       " 'herself': 813,\n",
       " 'parents': 814,\n",
       " 'famous': 815,\n",
       " 'imagine': 816,\n",
       " 'rent': 817,\n",
       " 'viewers': 818,\n",
       " 'crime': 819,\n",
       " 'richard': 820,\n",
       " 'form': 821,\n",
       " 'peter': 822,\n",
       " 'actual': 823,\n",
       " 'lady': 824,\n",
       " 'general': 825,\n",
       " 'dog': 826,\n",
       " 'follow': 827,\n",
       " 'believable': 828,\n",
       " 'period': 829,\n",
       " 'red': 830,\n",
       " 'brought': 831,\n",
       " 'move': 832,\n",
       " 'material': 833,\n",
       " 'forget': 834,\n",
       " 'somehow': 835,\n",
       " 'begins': 836,\n",
       " 're': 837,\n",
       " 'reviews': 838,\n",
       " 'animation': 839,\n",
       " 'paul': 840,\n",
       " \"you've\": 841,\n",
       " 'leads': 842,\n",
       " 'weak': 843,\n",
       " 'figure': 844,\n",
       " 'surprise': 845,\n",
       " 'sit': 846,\n",
       " 'hear': 847,\n",
       " 'average': 848,\n",
       " 'open': 849,\n",
       " 'sequences': 850,\n",
       " 'killing': 851,\n",
       " 'atmosphere': 852,\n",
       " 'eventually': 853,\n",
       " 'learn': 854,\n",
       " 'tom': 855,\n",
       " 'premise': 856,\n",
       " 'wait': 857,\n",
       " '20': 858,\n",
       " 'sci': 859,\n",
       " 'deep': 860,\n",
       " 'fi': 861,\n",
       " 'expected': 862,\n",
       " 'whatever': 863,\n",
       " 'indeed': 864,\n",
       " 'note': 865,\n",
       " 'particular': 866,\n",
       " 'lame': 867,\n",
       " 'poorly': 868,\n",
       " 'imdb': 869,\n",
       " 'dance': 870,\n",
       " 'situation': 871,\n",
       " 'shame': 872,\n",
       " 'third': 873,\n",
       " 'york': 874,\n",
       " 'box': 875,\n",
       " 'truth': 876,\n",
       " 'decided': 877,\n",
       " 'free': 878,\n",
       " 'hot': 879,\n",
       " \"who's\": 880,\n",
       " 'difficult': 881,\n",
       " 'needed': 882,\n",
       " 'season': 883,\n",
       " 'acted': 884,\n",
       " 'leaves': 885,\n",
       " 'unless': 886,\n",
       " 'possibly': 887,\n",
       " 'romance': 888,\n",
       " 'emotional': 889,\n",
       " 'gay': 890,\n",
       " 'sexual': 891,\n",
       " 'boys': 892,\n",
       " 'footage': 893,\n",
       " 'write': 894,\n",
       " 'western': 895,\n",
       " 'credits': 896,\n",
       " 'forced': 897,\n",
       " 'memorable': 898,\n",
       " 'reading': 899,\n",
       " 'became': 900,\n",
       " 'doctor': 901,\n",
       " 'otherwise': 902,\n",
       " 'crew': 903,\n",
       " 'begin': 904,\n",
       " 'air': 905,\n",
       " 'de': 906,\n",
       " 'question': 907,\n",
       " 'meet': 908,\n",
       " 'society': 909,\n",
       " 'male': 910,\n",
       " 'meets': 911,\n",
       " \"let's\": 912,\n",
       " 'plus': 913,\n",
       " 'cheesy': 914,\n",
       " 'hands': 915,\n",
       " 'superb': 916,\n",
       " 'screenplay': 917,\n",
       " 'beauty': 918,\n",
       " 'interested': 919,\n",
       " 'street': 920,\n",
       " 'features': 921,\n",
       " 'perfectly': 922,\n",
       " 'masterpiece': 923,\n",
       " 'whom': 924,\n",
       " 'laughs': 925,\n",
       " 'nature': 926,\n",
       " 'stage': 927,\n",
       " 'effect': 928,\n",
       " 'forward': 929,\n",
       " 'comment': 930,\n",
       " 'nor': 931,\n",
       " 'sounds': 932,\n",
       " 'badly': 933,\n",
       " 'previous': 934,\n",
       " 'e': 935,\n",
       " 'japanese': 936,\n",
       " 'weird': 937,\n",
       " 'island': 938,\n",
       " 'personal': 939,\n",
       " 'inside': 940,\n",
       " 'quickly': 941,\n",
       " 'total': 942,\n",
       " 'keeps': 943,\n",
       " 'towards': 944,\n",
       " 'result': 945,\n",
       " 'america': 946,\n",
       " 'crazy': 947,\n",
       " 'battle': 948,\n",
       " 'worked': 949,\n",
       " 'incredibly': 950,\n",
       " 'setting': 951,\n",
       " 'earlier': 952,\n",
       " 'background': 953,\n",
       " 'mess': 954,\n",
       " 'cop': 955,\n",
       " 'writers': 956,\n",
       " 'fire': 957,\n",
       " 'copy': 958,\n",
       " 'realize': 959,\n",
       " 'dumb': 960,\n",
       " 'unique': 961,\n",
       " 'powerful': 962,\n",
       " 'mark': 963,\n",
       " 'lee': 964,\n",
       " 'business': 965,\n",
       " 'rate': 966,\n",
       " 'dramatic': 967,\n",
       " 'older': 968,\n",
       " 'pay': 969,\n",
       " 'following': 970,\n",
       " 'joke': 971,\n",
       " 'girlfriend': 972,\n",
       " 'directors': 973,\n",
       " 'plenty': 974,\n",
       " 'directing': 975,\n",
       " 'various': 976,\n",
       " 'creepy': 977,\n",
       " 'baby': 978,\n",
       " 'development': 979,\n",
       " 'appear': 980,\n",
       " 'brings': 981,\n",
       " 'front': 982,\n",
       " 'dream': 983,\n",
       " 'ask': 984,\n",
       " 'water': 985,\n",
       " 'admit': 986,\n",
       " 'rich': 987,\n",
       " 'bill': 988,\n",
       " 'apart': 989,\n",
       " 'joe': 990,\n",
       " 'fairly': 991,\n",
       " 'political': 992,\n",
       " 'reasons': 993,\n",
       " 'leading': 994,\n",
       " 'portrayed': 995,\n",
       " 'spent': 996,\n",
       " 'telling': 997,\n",
       " 'cover': 998,\n",
       " 'outside': 999,\n",
       " 'fighting': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV\\'s \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina\\'s pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D\\'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary\\'s Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1153, 182, 17, 1066, 16, 815, 1457, 18, 2602, 31, 7951, 305, 4, 7888, 1210, 14, 3, 180, 18, 672, 8306, 2196, 16, 3, 1861, 35, 6, 5, 969, 15, 40, 3138, 31, 1, 5, 603, 1, 134, 16, 7951, 23, 52, 69, 1819, 1, 1245, 207, 6, 399, 8161, 6, 1313, 14, 4989, 18, 50, 7951, 1121, 82, 3, 977, 5103, 5663, 8770, 31, 3, 1998, 1982, 20, 1, 342, 1862, 177, 62, 375, 6187, 1, 5030, 585, 3, 8697, 3542, 8230, 2, 8458, 374, 7952, 2079, 5422, 23, 3, 9719, 169, 2, 9935, 6, 78, 245, 14, 3, 571, 1361, 1, 17, 6, 800, 3, 1631, 4, 8771, 978, 2, 1, 5031, 18, 48, 3, 2174, 441, 20, 1, 116, 31, 4423, 1, 8847, 6, 3746, 363, 4, 7017, 831, 122, 69, 31, 164, 498, 2297, 35, 3, 9311, 272, 16, 2788, 307, 230, 36]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221.27716"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2209"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "544"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94532"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncating: \"pre\" or \"post\" are parameters. Truncate the tokenized list of words\n",
    "# that is longer than the maximum length defined by maxlen, by filling zeros forward\n",
    "# or backward.\n",
    "pad = \"pre\"\n",
    "x_train_pad = pad_sequences(x_train_tokens,\n",
    "                            maxlen=max_tokens,\n",
    "                            padding=pad,\n",
    "                            truncating=pad)\n",
    "x_test_pad = pad_sequences(x_test_tokens,\n",
    "                           maxlen=max_tokens,\n",
    "                           padding=pad,\n",
    "                           truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 544) (25000, 544)\n"
     ]
    }
   ],
   "source": [
    "# 25000 tokenized texts (train and test), each has 544 dimentions in length.\n",
    "print(x_train_pad.shape, x_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1153, 182, 17, 1066, 16, 815, 1457, 18, 2602, 31, 7951, 305, 4, 7888, 1210, 14, 3, 180, 18, 672, 8306, 2196, 16, 3, 1861, 35, 6, 5, 969, 15, 40, 3138, 31, 1, 5, 603, 1, 134, 16, 7951, 23, 52, 69, 1819, 1, 1245, 207, 6, 399, 8161, 6, 1313, 14, 4989, 18, 50, 7951, 1121, 82, 3, 977, 5103, 5663, 8770, 31, 3, 1998, 1982, 20, 1, 342, 1862, 177, 62, 375, 6187, 1, 5030, 585, 3, 8697, 3542, 8230, 2, 8458, 374, 7952, 2079, 5422, 23, 3, 9719, 169, 2, 9935, 6, 78, 245, 14, 3, 571, 1361, 1, 17, 6, 800, 3, 1631, 4, 8771, 978, 2, 1, 5031, 18, 48, 3, 2174, 441, 20, 1, 116, 31, 4423, 1, 8847, 6, 3746, 363, 4, 7017, 831, 122, 69, 31, 164, 498, 2297, 35, 3, 9311, 272, 16, 2788, 307, 230, 36]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0, 1153,  182,   17, 1066,   16,  815, 1457,   18, 2602,   31,\n",
       "       7951,  305,    4, 7888, 1210,   14,    3,  180,   18,  672, 8306,\n",
       "       2196,   16,    3, 1861,   35,    6,    5,  969,   15,   40, 3138,\n",
       "         31,    1,    5,  603,    1,  134,   16, 7951,   23,   52,   69,\n",
       "       1819,    1, 1245,  207,    6,  399, 8161,    6, 1313,   14, 4989,\n",
       "         18,   50, 7951, 1121,   82,    3,  977, 5103, 5663, 8770,   31,\n",
       "          3, 1998, 1982,   20,    1,  342, 1862,  177,   62,  375, 6187,\n",
       "          1, 5030,  585,    3, 8697, 3542, 8230,    2, 8458,  374, 7952,\n",
       "       2079, 5422,   23,    3, 9719,  169,    2, 9935,    6,   78,  245,\n",
       "         14,    3,  571, 1361,    1,   17,    6,  800,    3, 1631,    4,\n",
       "       8771,  978,    2,    1, 5031,   18,   48,    3, 2174,  441,   20,\n",
       "          1,  116,   31, 4423,    1, 8847,    6, 3746,  363,    4, 7017,\n",
       "        831,  122,   69,   31,  164,  498, 2297,   35,    3, 9311,  272,\n",
       "         16, 2788,  307,  230,   36], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: why are we truncating the text forward, i.e. filling zeros front?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer Inverse Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper-function for converting a list of tokens back to a string of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens):\n",
    "    # Helper-function for converting a list of tokens back to a string of words.\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bizarre horror movie filled with famous faces but stolen by Cristina Raines (later of TV\\'s \"Flamingo Road\") as a pretty but somewhat unstable model with a gummy smile who is slated to pay for her attempted suicides by guarding the Gateway to Hell! The scenes with Raines modeling are very well captured, the mood music is perfect, Deborah Raffin is charming as Cristina\\'s pal, but when Raines moves into a creepy Brooklyn Heights brownstone (inhabited by a blind priest on the top floor), things really start cooking. The neighbors, including a fantastically wicked Burgess Meredith and kinky couple Sylvia Miles & Beverly D\\'Angelo, are a diabolical lot, and Eli Wallach is great fun as a wily police detective. The movie is nearly a cross-pollination of \"Rosemary\\'s Baby\" and \"The Exorcist\"--but what a combination! Based on the best-seller by Jeffrey Konvitz, \"The Sentinel\" is entertainingly spooky, full of shocks brought off well by director Michael Winner, who mounts a thoughtfully downbeat ending with skill. ***1/2 from ****'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1153, 182, 17, 1066, 16, 815, 1457, 18, 2602, 31, 7951, 305, 4, 7888, 1210, 14, 3, 180, 18, 672, 8306, 2196, 16, 3, 1861, 35, 6, 5, 969, 15, 40, 3138, 31, 1, 5, 603, 1, 134, 16, 7951, 23, 52, 69, 1819, 1, 1245, 207, 6, 399, 8161, 6, 1313, 14, 4989, 18, 50, 7951, 1121, 82, 3, 977, 5103, 5663, 8770, 31, 3, 1998, 1982, 20, 1, 342, 1862, 177, 62, 375, 6187, 1, 5030, 585, 3, 8697, 3542, 8230, 2, 8458, 374, 7952, 2079, 5422, 23, 3, 9719, 169, 2, 9935, 6, 78, 245, 14, 3, 571, 1361, 1, 17, 6, 800, 3, 1631, 4, 8771, 978, 2, 1, 5031, 18, 48, 3, 2174, 441, 20, 1, 116, 31, 4423, 1, 8847, 6, 3746, 363, 4, 7017, 831, 122, 69, 31, 164, 498, 2297, 35, 3, 9311, 272, 16, 2788, 307, 230, 36]\n"
     ]
    }
   ],
   "source": [
    "print(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recreate this text except for punctuation and other symbols, by converting the list of tokens back to words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"bizarre horror movie filled with famous faces but stolen by raines later of tv's road as a pretty but somewhat unstable model with a smile who is to pay for her attempted by the to hell the scenes with raines are very well captured the mood music is perfect deborah is charming as pal but when raines moves into a creepy brooklyn heights inhabited by a blind priest on the top floor things really start cooking the neighbors including a fantastically wicked meredith and kinky couple sylvia miles beverly are a diabolical lot and eli is great fun as a police detective the movie is nearly a cross of rosemary's baby and the exorcist but what a combination based on the best by jeffrey the sentinel is spooky full of shocks brought off well by director michael winner who a downbeat ending with skill 1 2 from\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_to_string(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU\n",
    "We are going to use GRU as a cell of RNN.\n",
    "\n",
    "![GRU Architecture and Equations](img/GRU.png)\n",
    "\n",
    "\n",
    "Original Paper Source: https://arxiv.org/pdf/1406.1078v3.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words: the vocabulary size used as an input, 10000 in our case since we chose top 10000 frequent words.\n",
    "# output_dim: arbitrary dimension of embedding output layer.\n",
    "# input_length: the maximum length of the input sequence, in our case 544.\n",
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# units: positive integer, that is the size of output dimension.\n",
    "model.add(GRU(units=16, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=8, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam (Adaptive moment estimation)\n",
    "Now we are going to use the optimizer called Adam, which is one of the many optimizers, definition delineated below. It was developed in 2015 by group of authers including Diederik P. Kingma. It has relatively high learning efficiency, however it does not necessary guarantee that Adam should be used for all datasets and networks.\n",
    "\n",
    "Given parameters $w^{(t)}$ and a loss function $L^{(t)}$, where $t$ indexes the current training iteration (indexed at $0$), Adam's parameter update is given by:\n",
    "\\begin{equation*}\n",
    "m_w ^ {(t+1)} \\leftarrow \\beta_1 m_w ^ {(t)} + (1 - \\beta_1) \\nabla _w L ^ {(t)}\\\\\n",
    "v_w ^ {(t+1)} \\leftarrow \\beta_2 v_w ^ {(t)} + (1 - \\beta_2) (\\nabla _w L ^ {(t)})^2\\\\\n",
    "\\hat{m}_w = \\frac{m_w ^ {(t+1)}}{1 - \\beta_1 ^{t+1}}\\\\\n",
    "\\hat{v}_w = \\frac{ v_w ^ {(t+1)}}{1 - \\beta_2 ^{t+1}}\\\\\n",
    "w ^ {(t+1)} \\leftarrow w ^ {(t)} - \\eta \\frac{\\hat{m}_w}{\\sqrt{\\hat{v}_w} + \\epsilon}\\\\\n",
    "\\end{equation*}\n",
    "where $\\epsilon$  is a small scalar used to prevent division by $0$, and $\\beta _1$ and $\\beta _2$ are the forgetting factors for gradients and second moments of gradients, respectively. Squaring and square-rooting is done elementwise.\n",
    "\n",
    "Recommended values for parameters in the paper:\n",
    "$\\eta=0.001, \\beta_1=0.9, \\beta_2=0.999, \\epsilon=10^{-8}$\n",
    "and $m_0=0, v_0=0$ for initial values.\n",
    "\n",
    "Original Paper Source: https://arxiv.org/pdf/1412.6980.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compile the defined model for it to be ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 544, 8)            80000     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 16)          1200      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 8)           600       \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 4)                 156       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 81,961\n",
      "Trainable params: 81,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the defined RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23750 samples, validate on 1250 samples\n",
      "Epoch 1/3\n",
      "23750/23750 [==============================]23750/23750 [==============================] - 382s 16ms/step - loss: 0.6729 - acc: 0.5744 - val_loss: 0.6416 - val_acc: 0.6384\n",
      "\n",
      "Epoch 2/3\n",
      "23750/23750 [==============================]23750/23750 [==============================] - 368s 15ms/step - loss: 0.4486 - acc: 0.7921 - val_loss: 0.0639 - val_acc: 0.9976\n",
      "\n",
      "Epoch 3/3\n",
      "23750/23750 [==============================]23750/23750 [==============================] - 377s 16ms/step - loss: 0.3133 - acc: 0.8733 - val_loss: 0.6484 - val_acc: 0.7200\n",
      "\n",
      "CPU times: user 32min 21s, sys: 9min 20s, total: 41min 41s\n",
      "Wall time: 18min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1819fcd390>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_pad,\n",
    "          y_train,\n",
    "          validation_split=0.05, \n",
    "          epochs=3, \n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save(filepath) enables you to save a model as HDF5 file.\n",
    "HDF5 file contains the following items:\n",
    "<ul>\n",
    "  <li>Model structure that can be reconstracted</li>\n",
    "  <li>Weights of model</li>\n",
    "  <li>Learning parameter setting: loss, optimizer</li>\n",
    "  <li>Status of the optimizer, so that after the end of training, it enables smooth starts of the retraining</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example:\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also save only the model architecture by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save as JSON\n",
    "# json_string = model.to_json()\n",
    "\n",
    "# # save as YAML\n",
    "# yaml_string = model.to_yaml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details refer to the keras offical documents:\n",
    "https://keras.io/ja/getting-started/faq/#keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/model_1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance on Test-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model/model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================]25000/25000 [==============================] - 115s 5ms/step\n",
      "\n",
      "CPU times: user 3min 40s, sys: 1min 4s, total: 4min 45s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model.evaluate(x_test_pad, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 83.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"model/model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text0 = \"This is excellent! This is by far the best movie I have ever seen in my life!\"\n",
    "text1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
    "text2 = \"Good movie!\"\n",
    "text3 = \"Maybe I like this movie.\"\n",
    "text4 = \"Meh ...\"\n",
    "text5 = \"If I were a drunk teenager then this movie might be good.\"\n",
    "text6 = \"Bad movie!\"\n",
    "text7 = \"Not a good movie!\"\n",
    "text8 = \"This movie really sucks! Can I get my money back please?\"\n",
    "text9 = \"This is a complete waste of time. The worst movie ever!\"\n",
    "texts = [text0, text1, text2, text3, text4, text5, text6, text7, text8, text9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 544)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_pad = pad_sequences(tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "tokens_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92068624]\n",
      " [0.8908813 ]\n",
      " [0.87077683]\n",
      " [0.48089698]\n",
      " [0.8431827 ]\n",
      " [0.36755407]\n",
      " [0.52853155]\n",
      " [0.74753517]\n",
      " [0.1889803 ]\n",
      " [0.05744076]]\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(tokens_pad)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The closer a value is to $0$ more negative sentiment it has and the closer it is to $1$ more positie sentiment it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
